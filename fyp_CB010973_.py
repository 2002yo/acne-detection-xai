# -*- coding: utf-8 -*-
"""FYP - MID POINT PROGRESS NEW .ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1bVA9SqU9sIPdKFckO-p9TPREnrqFAsu_
"""

!nvidia-smi

import torch
print("GPU Available:", torch.cuda.is_available())
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU")

"""# DATASET Verification"""

from google.colab import drive
drive.mount('/content/drive')

import os

dataset_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8"

# Check if the dataset folder exists
if os.path.exists(dataset_path):
    print(" Dataset found!")
    print("Contents:", os.listdir(dataset_path))
else:
    print(" Dataset not found. Check the path!")

# List folders inside dataset
print("Dataset structure:", os.listdir(dataset_path))

# Count images and labels
train_images = len(os.listdir(f"{dataset_path}/train/images"))
train_labels = len(os.listdir(f"{dataset_path}/train/labels"))
valid_images = len(os.listdir(f"{dataset_path}/valid/images"))
valid_labels = len(os.listdir(f"{dataset_path}/valid/labels"))
test_images = len(os.listdir(f"{dataset_path}/test/images"))
test_labels = len(os.listdir(f"{dataset_path}/test/labels"))

print(f"Train: {train_images} images, {train_labels} labels")
print(f"Valid: {valid_images} images, {valid_labels} labels")
print(f"Test: {test_images} images, {test_labels} labels")

# Show a sample label file
label_path = f"{dataset_path}/train/labels"
sample_label = os.listdir(label_path)[0]  # Pick a random label file

with open(os.path.join(label_path, sample_label), "r") as file:
    label_data = file.readlines()

print(f"Sample label ({sample_label}):\n", label_data)

"""# Verfying the bounding boxes in images accessing an image"""

!pip install ultralytics opencv-python matplotlib pyyaml

import os

dataset_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8"
images_path = os.path.join(dataset_path, "train", "images")
labels_path = os.path.join(dataset_path, "train", "labels")
yaml_path = os.path.join(dataset_path, "data.yaml")  # Path to class names

import yaml

# Load class names from data.yaml
with open(yaml_path, "r") as f:
    data = yaml.safe_load(f)

class_names = data["names"]

# Get the number of classes
num_classes = len(class_names)

# Print the result
print("Number of classes:", num_classes)

import yaml

# Load class names from data.yaml
with open(yaml_path, "r") as f:
    data = yaml.safe_load(f)
class_names = data["names"]

# Print class names to verify
print(" Class names loaded:", class_names)

import cv2
import matplotlib.pyplot as plt

def draw_bounding_boxes(image_path, label_path, class_names):
    # Load image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format

    # Get image dimensions
    h, w, _ = image.shape

    # Read label file
    if not os.path.exists(label_path):
        print(f" No label file found for {image_path}")
        return

    with open(label_path, "r") as file:
        labels = file.readlines()

    # Loop through each label and draw bounding boxes
    for label in labels:
        data = label.strip().split()
        class_id = int(data[0])  # Get class ID
        x_center, y_center, width, height = map(float, data[1:])  # Get bounding box

        # Convert YOLO format (normalized) to pixel values
        x_center, y_center, width, height = (
            int(x_center * w),
            int(y_center * h),
            int(width * w),
            int(height * h),
        )

        # Get box coordinates
        x1, y1, x2, y2 = (
            x_center - width // 2,
            y_center - height // 2,
            x_center + width // 2,
            y_center + height // 2,
        )

        # Draw bounding box
        color = (255, 0, 0)  # Red box
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

        # Display class name
        class_label = class_names[class_id] if class_id < len(class_names) else f"Class {class_id}"
        cv2.putText(image, class_label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Show image
    plt.figure(figsize=(8, 8))
    plt.imshow(image)
    plt.axis("off")
    plt.show()

import random

# Get a random image from the dataset
image_files = os.listdir(images_path)
sample_image = random.choice(image_files)  # Select a random image

# Define paths for image and corresponding label file
image_path = os.path.join(images_path, sample_image)
label_path = os.path.join(labels_path, sample_image.replace(".jpg", ".txt"))

# Check if label file exists
if os.path.exists(label_path):
    draw_bounding_boxes(image_path, label_path, class_names)
else:
    print(f"No label found for {sample_image}")

"""# Installing the dependencies for the training"""

!nvidia-smi

import torch
print("GPU Available:", torch.cuda.is_available())
print("GPU Name:", torch.cuda.get_device_name(0) if torch.cuda.is_available() else "No GPU")

!pip install pillow

!ls /content/acne_detection_yolov8/yolov8_finetune/weights

from google.colab import drive
drive.mount('/content/drive')

# Check your model path in Drive
!ls "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune/weights"

"""# Training the YOLOv8 MODEL"""

from ultralytics import YOLO

# Define dataset path
dataset_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8"

# Load YOLOv8 model (you can switch to 'yolov8l.pt' for more accuracy)
model = YOLO("yolov8m.pt")  # 'yolov8m.pt' balances speed & accuracy

# Start training
results = model.train(
    data=f"{dataset_path}/data.yaml",  # Path to dataset YAML file
    epochs=20,  # Number of training epochs
    imgsz=640,  # Image size for training
    batch=8,  # Increase batch size since A100 has more VRAM
    save=True,
    save_period=5,  # Save weights every 5 epochs
    project="/content/drive/My Drive/acne_detection_yolov8",  # Save in Google Drive
    name="yolov8_finetune",
    device="cuda",  # Use GPU
    workers=4,  # Use multiple workers for faster dataloading
    optimizer="AdamW",  # More stable optimizer for fine-tuning
    patience=5,  # Early stopping if no improvement
    lr0=0.001,  # Adjust learning rate (default is 0.01, lower for fine-tuning)
    momentum=0.9,  # Standard momentum for stable training
    weight_decay=0.0005,  # Helps with generalization
    dropout=0.1,  # Prevents overfitting
)

print("‚úÖ Training started on T4 GPU. Monitor logs for progress!")

from ultralytics import YOLO

# Load the best trained model
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune2/weights/best.pt")

print("‚úÖ Model loaded successfully. Ready for inference!")

import os
import glob
from PIL import Image
from IPython.display import display

# Get a test image (change the folder if needed)
test_image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/images/acne_sample.jpg"

# Ensure the image exists before inference
if os.path.exists(test_image_path):
    print(f"‚úÖ Running inference on: {test_image_path}")
    results = model.predict(source=test_image_path, imgsz=640, conf=0.3, save=True)

    # Locate and display the detected image
    output_folder = sorted(glob.glob("/content/runs/detect/*"), key=os.path.getmtime, reverse=True)[0]  # Get latest output folder
    saved_images = os.listdir(output_folder)

    if saved_images:
        detected_image_path = os.path.join(output_folder, saved_images[0])
        print(f"üì∏ Showing detected image: {detected_image_path}")
        display(Image.open(detected_image_path))
    else:
        print("‚ùå No detected image found!")

else:
    print("‚ùå Test image not found. Check the path and try again.")

"""# Retrained the model"""

results = model.train(
    data=f"{dataset_path}/data.yaml",
    epochs=30,  #  epochs
    imgsz=640,
    batch=8,
    save=True,
    project="/content/drive/My Drive/acne_detection_yolov8",
    name="yolov8_finetune3",
    device="cuda",
    optimizer="AdamW",
    lr0=0.0005,  # Lower learning rate to prevent overfitting
    dropout=0.2,  # Improve generalization
)

from ultralytics import YOLO

# Load the best trained model for testing
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt")

print("‚úÖ Model loaded successfully. Ready for inference!")

from ultralytics import YOLO

# Load the best trained model for testing
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt")

import glob

# Find all available test images
test_images = glob.glob("/content/drive/My Drive/Datasets/Acne Detection YOLOv8/images/*.jpg")

if test_images:
    test_image_path = test_images[0]  # Pick the first available image
    print(f"‚úÖ Using test image: {test_image_path}")
else:
    print("‚ùå No images found in the directory.")

import os

test_image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images/acne-341_jpeg_jpg.rf.a05c2db7a0e80eba5b6119004cae2684.jpg"

if os.path.exists(test_image_path):
    print("‚úÖ The test image exists.")
else:
    print("‚ùå The test image does not exist. Check the file path.")

import os

test_image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images/acne-341_jpeg_jpg.rf.a05c2db7a0e80eba5b6119004cae2684.jpg"

if os.path.exists(test_image_path):
    print("‚úÖ The test image exists.")
else:
    print("‚ùå The test image does NOT exist. Check the file path.")

import os
from PIL import Image
from IPython.display import display
from ultralytics import YOLO

# Load the best trained model for testing
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt")

# Define the test image path
test_image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images/acne-341_jpeg_jpg.rf.a05c2db7a0e80eba5b6119004cae2684.jpg"

# Run inference with adjusted confidence threshold
results = model.predict(source=test_image_path, imgsz=640, conf=0.3, save=True)

# Locate and display the detected image
output_folder = "/content/runs/detect/predict"
saved_images = os.listdir(output_folder)

if saved_images:
    detected_image_path = os.path.join(output_folder, saved_images[0])
    print(f"üì∏ Showing detected image: {detected_image_path}")
    display(Image.open(detected_image_path))
else:
    print("‚ùå No detected image found!")

import random
import glob

# Define paths for images
image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images"

# Get a list of all image files
train_images = glob.glob(f"{image_path}/*.jpg") + glob.glob(f"{image_path}/*.png") + glob.glob(f"{image_path}/*.jpeg")

# Pick a random image
if train_images:
    test_image_path = random.choice(train_images)
    print(f"üì∏ Selected Random Image: {test_image_path}")
else:
    print("‚ùå No images found in the dataset!")

from ultralytics import YOLO
import os
from PIL import Image
from IPython.display import display

# Load the trained model
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt")

# Run inference
results = model.predict(source=test_image_path, imgsz=640, conf=0.3, save=True)

# Locate and display the detected image
output_folder = "/content/runs/detect/predict"
saved_images = os.listdir(output_folder)

if saved_images:
    detected_image_path = os.path.join(output_folder, saved_images[0])
    print(f"üì∏ Showing detected image: {detected_image_path}")
    display(Image.open(detected_image_path))
else:
    print("‚ùå No detected image found!")

# Loop through detected objects
for result in results:
    for box in result.boxes:
        class_id = int(box.cls[0])  # Get class ID
        confidence = float(box.conf[0])  # Get confidence score
        bbox = [round(i, 2) for i in box.xyxy[0].tolist()]  # Get bounding box

        # Get class name from model class list
        acne_class = model.names[class_id]

        # Extract severity from the class name (assuming format AcneType_Severity)
        severity = acne_class.split('_')[-1] if '_' in acne_class else "Unknown"

        # Print results
        print(f"‚úÖ Detected Acne: {acne_class} | Severity: {severity} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")

if len(results[0].boxes) == 0:
    print("‚ùå No acne detected in this image.")
else:
    print("‚úÖ Acne detected!")

import glob

output_dirs = sorted(glob.glob("/content/runs/detect/*"), key=os.path.getmtime, reverse=True)

if output_dirs:
    latest_output = output_dirs[0]
    print(f"‚úÖ Latest YOLO output folder: {latest_output}")
else:
    print("‚ùå No YOLO output folders found.")

import os

output_folder = "/content/runs/detect/predict2"
saved_images = os.listdir(output_folder)

if saved_images:
    print("üì∏ Saved YOLO Output Image:", saved_images)
else:
    print("‚ùå No images found.")

from IPython.display import display
from PIL import Image

output_image_path = os.path.join(output_folder, saved_images[0])  # Pick first saved image

display(Image.open(output_image_path))

"""# Fine tuning the Best Model"""

model_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune5/weights/best.pt"
print(f"‚úÖ Model path is: {model_path}")

from ultralytics import YOLO

# Load the best trained model for fine-tuning
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt")

# Define dataset path
dataset_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8"

# Start fine-tuning
results = model.train(
    data=f"{dataset_path}/data.yaml",  # Path to dataset YAML file
    epochs=30,  # More epochs for better learning
    imgsz=640,  # Image size
    batch=8,  # Adjust based on GPU memory
    save=True,
    project="/content/drive/My Drive/acne_detection_yolov8",
    name="yolov8_finetune4",  # A new version
    device="cuda",  # Use GPU
    patience=10,  # Prevent early stopping
    optimizer="AdamW",  # Better optimization
    lr0=0.0005,  # Lower learning rate to prevent overfitting
    dropout=0.2,  # Reduce overfitting
    mosaic=1.0,  # Enable data augmentation
)

print("‚úÖ Fine-tuning started. Monitor training logs for progress!")

from ultralytics import YOLO

# Load the trained model
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt")

import os

test_image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images/acne-341_jpeg_jpg.rf.a05c2db7a0e80eba5b6119004cae2684.jpg"

# Check if the file exists
if os.path.exists(test_image_path):
    print("‚úÖ Test image found:", test_image_path)
else:
    print("‚ùå Test image NOT found. Check the path!")

results = model.val()

import random
import glob

# Define paths for images
image_path = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/train/images"

# Get a list of all image files
train_images = glob.glob(f"{image_path}/*.jpg") + glob.glob(f"{image_path}/*.png") + glob.glob(f"{image_path}/*.jpeg")

# Pick a random image
if train_images:
    test_image_path = random.choice(train_images)
    print(f"üì∏ Selected Random Image: {test_image_path}")
else:
    print("‚ùå No images found in the dataset!")

"""# Result of Fine Tuned Model"""

import os

model_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt"

if os.path.exists(model_path):
    print("‚úÖ Model found:", model_path)
else:
    print("‚ùå Model file missing! Check the path.")

model.val()

from ultralytics import YOLO
from PIL import Image
from IPython.display import display
import os
import random
import glob
import cv2
import matplotlib.pyplot as plt

# Load the trained YOLOv8 model
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt")

# Define test image directory
test_image_dir = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/images"

# Get a list of all test images
test_images = glob.glob(f"{test_image_dir}/*.jpg") + glob.glob(f"{test_image_dir}/*.png") + glob.glob(f"{test_image_dir}/*.jpeg")

# Pick a random test image
if test_images:
    test_image_path = random.choice(test_images)
    print(f"üì∏ Selected Random Image: {test_image_path}")
else:
    print("‚ùå No test images found!")
    test_image_path = None

# Run inference only if an image was selected
if test_image_path:
    results = model.predict(source=test_image_path, imgsz=640, conf=0.1, save=True)  # Lower conf threshold to detect more

    # Load the original image
    image = cv2.imread(test_image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert from BGR to RGB for correct display in matplotlib

    # Check if any detections were found
    if not results[0].boxes or len(results[0].boxes) == 0:
        print("‚ùå No acne detected in this image.")
    else:
        print("\nüîç **Detection Results:**")
        for box in results[0].boxes:
            class_id = int(box.cls[0])  # Class ID
            confidence = float(box.conf[0])  # Confidence score
            bbox = [round(i, 2) for i in box.xyxy[0].tolist()]  # Bounding box coordinates
            acne_class = model.names[class_id]  # Get class name

            print(f"‚úÖ Detected Acne: {acne_class} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")

            # Draw bounding boxes on the image
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box
            cv2.putText(image, f"{acne_class} ({confidence:.2f})", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # Display the image with detections
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    plt.axis("off")  # Hide axes
    plt.title("Detected Acne")
    plt.show()

"""# Test Results

"""

from ultralytics import YOLO
import numpy as np
import glob
import cv2
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from tqdm import tqdm  # For progress tracking

# Load the trained YOLO model
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt")

# Define test image directory and label directory
test_image_dir = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/images"
label_dir = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/labels"  # Assuming YOLO format

# Get test images
test_images = glob.glob(f"{test_image_dir}/*.jpg") + glob.glob(f"{test_image_dir}/*.png") + glob.glob(f"{test_image_dir}/*.jpeg")

# Initialize lists to store true labels and predicted scores
y_true = []
y_scores = []

# Process each test image
for image_path in tqdm(test_images, desc="Processing Test Images"):
    # Get corresponding label file (assumes YOLO format)
    label_path = label_dir + "/" + os.path.basename(image_path).replace(".jpg", ".txt").replace(".png", ".txt").replace(".jpeg", ".txt")

    # Read ground truth labels (YOLO format: class_id x_center y_center width height)
    if os.path.exists(label_path):
        with open(label_path, "r") as file:
            lines = file.readlines()
            ground_truth_classes = [int(line.split()[0]) for line in lines]  # Extract class IDs
    else:
        ground_truth_classes = []  # No labels mean no detections

    # Run inference on image
    results = model.predict(source=image_path, imgsz=640, conf=0.1)

    # Process results
    for result in results:
        if result.boxes is not None and len(result.boxes) > 0:
            for box in result.boxes:
                class_id = int(box.cls[0])  # Predicted class ID
                confidence = float(box.conf[0])  # Confidence score

                # Append results for AUC-ROC evaluation
                y_true.append(1 if class_id in ground_truth_classes else 0)  # 1 if correctly detected, 0 otherwise
                y_scores.append(confidence)

# Compute ROC Curve
fpr, tpr, _ = roc_curve(y_true, y_scores)
roc_auc = auc(fpr, tpr)

# Plot ROC Curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC Curve (AUC = {roc_auc:.2f})')
plt.plot([0, 1], [0, 1], color='gray', linestyle='--')  # Diagonal line for random chance
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend(loc="lower right")
plt.grid()
plt.show()

# Print AUC score
print(f"\nüéØ **AUC Score:** {roc_auc:.4f}")

from ultralytics import YOLO
model = YOLO("/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune4/weights/best.pt")

import random
import glob

test_image_dir = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/images"
test_images = glob.glob(f"{test_image_dir}/*.jpg") + glob.glob(f"{test_image_dir}/*.png") + glob.glob(f"{test_image_dir}/*.jpeg")

if test_images:
    test_image_path = random.choice(test_images)
    print(f"üì∏ Selected Random Image: {test_image_path}")
else:
    print("‚ùå No test images found!")

results = model.predict(source=test_image_path, imgsz=640, conf=0.1, save=True)  # Lower confidence to detect more

for result in results:
    for box in result.boxes:
        class_id = int(box.cls[0])
        confidence = float(box.conf[0])
        bbox = [round(i, 2) for i in box.xyxy[0].tolist()]
        acne_class = model.names[class_id]

        print(f"‚úÖ Detected Acne: {acne_class} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")

from PIL import Image
from IPython.display import display
import cv2
import matplotlib.pyplot as plt
import os

# Load original image
image = cv2.imread(test_image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Draw bounding boxes on the image
if not results[0].boxes or len(results[0].boxes) == 0:
    print("‚ùå No acne detected in this image.")
else:
    for box in results[0].boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
        acne_class = model.names[int(box.cls[0])]
        confidence = float(box.conf[0])

        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)  # Green box
        cv2.putText(image, f"{acne_class} ({confidence:.2f})", (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.axis("off")
plt.title("Detected Acne")
plt.show()

"""# Saved Model

"""

from ultralytics import YOLO

# Path to your trained model in Google Drive
model_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune4/weights/best.pt"

# Check if the model file exists
import os
if os.path.exists(model_path):
    print("‚úÖ Model found! Loading...")
    model = YOLO(model_path)  # Load the trained YOLOv8 model
else:
    print("‚ùå Model file not found! Check the path.")

from shutil import copyfile

# Define model path
src_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune4/weights/best.pt"
backup_path = "/content/drive/My Drive/YOLOv8_Backups/best_backup.pt"

# Create a backup
copyfile(src_path, backup_path)
print("‚úÖ Model backup saved successfully!")

from ultralytics import YOLO

# Mount Drive
from google.colab import drive
drive.mount('/content/drive')

# Load model from backup
model = YOLO("/content/drive/My Drive/YOLOv8_Backups/best_backup.pt")
print("‚úÖ Model loaded successfully!")

from google.colab import files

model_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune4/weights/best.pt"

# Download the model file
files.download(model_path)
print("‚úÖ Model downloaded successfully!")

torch.save(model.state_dict(), '/content/drive/My Drive/my_model.pt')

"""*italicized text*# New Section"""

from google.colab import drive
drive.mount('/content/drive')

import os

search_path = '/content/drive/My Drive'

for root, dirs, files in os.walk(search_path):
    for file in files:
        if file.endswith('.pt'):
            print(os.path.join(root, file))

from ultralytics import YOLO

model_path = '/content/drive/My Drive/YOLOv8_Backups/best_backup.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune3/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune2/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune4/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune32/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

from ultralytics import YOLO

model_path = '/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune5/weights/best.pt'
model = YOLO(model_path)

# Evaluate model performance on validation set
results = model.val()

!pip install ultralytics

# Step 2: Import libraries
from ultralytics import YOLO
from PIL import Image
import matplotlib.pyplot as plt
import cv2
import os
import random
import glob

# Step 3: Define model and image directory
model_path = "/content/drive/My Drive/acne_detection_yolov8/yolov8_finetune43/weights/best.pt"
test_image_dir = "/content/drive/My Drive/Datasets/Acne Detection YOLOv8/test/images"

# Load the YOLOv8 model
model = YOLO(model_path)

# Get all jpg/jpeg/png images in the test folder
test_images = glob.glob(f"{test_image_dir}/*.jpg") + glob.glob(f"{test_image_dir}/*.jpeg") + glob.glob(f"{test_image_dir}/*.png")

# Choose a random image
if not test_images:
    raise FileNotFoundError("‚ùå No test images found!")

test_image_path = random.choice(test_images)
print(f"üì∏ Selected Random Test Image: {test_image_path}")

# Step 4: Run YOLOv8 prediction
results = model.predict(source=test_image_path, imgsz=640, conf=0.1, save=True)

# Step 5: Print detections
for result in results:
    if result.boxes:
        for box in result.boxes:
            class_id = int(box.cls[0])
            confidence = float(box.conf[0])
            bbox = [round(coord, 2) for coord in box.xyxy[0].tolist()]
            acne_class = model.names[class_id]
            print(f"‚úÖ Detected Acne: {acne_class} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")
    else:
        print("‚ùå No detections found in this image.")

# Step 6: Draw results with OpenCV
image = cv2.imread(test_image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

for box in results[0].boxes:
    x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
    class_id = int(box.cls[0])
    confidence = float(box.conf[0])
    acne_class = model.names[class_id]

    cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
    cv2.putText(image, f"{acne_class} ({confidence:.2f})", (x1, y1 - 10),
                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

# Display the image
plt.figure(figsize=(10, 10))
plt.imshow(image)
plt.axis("off")
plt.title("Detected Acne")
plt.show()



"""# Final Model Training

# Dataset Verification Before Model Training - ***FINAL MODEL***
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/Datasets/Acne Detection with YOLOv8

!pip install ultralytics

import os

dataset_path = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8"

# Check if the dataset folder exists
if os.path.exists(dataset_path):
    print("‚úÖ Dataset folder found!")
    print("üìÅ Contents:", os.listdir(dataset_path))
else:
    print("‚ùå Dataset not found. Please check the path.")

# Commented out IPython magic to ensure Python compatibility.
# Change to dataset directory
# %cd /content/drive/MyDrive/Datasets/Acne Detection with YOLOv8

# List all folders and subfolders
!ls -R

# Display the YAML configuration file
!cat data.yaml

import torch

if torch.cuda.is_available():
    print("‚úÖ GPU is available:", torch.cuda.get_device_name(0))
else:
    print("‚ö†Ô∏è GPU not available. Check runtime settings.")

"""# Bounding Box Verification

## ‚ùå Bounding Box Verification Using Random Image Selection (Unreliable Results)
This method randomly selected test images for bounding box visualization, but produced false warnings due to missing `.txt` files or invalid class IDs that were not present in the dataset. Not suitable for complete verification.
"""

import os
import random
import cv2
import matplotlib.pyplot as plt

# Set paths
image_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images"
label_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/labels"

# Class names
class_names = ['blackhead', 'whitehead', 'papule', 'pustule', 'cystic', 'nodular']

def show_random_labeled_image():
    image_files = [f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.jpeg', '.png'))]
    if not image_files:
        print("‚ùå No images found in test/images/")
        return

    selected_img = random.choice(image_files)
    img_path = os.path.join(image_dir, selected_img)
    label_path = os.path.join(label_dir, os.path.splitext(selected_img)[0] + '.txt')

    img = cv2.imread(img_path)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
    h, w, _ = img.shape

    # ‚úÖ Start block here
    if os.path.exists(label_path):
        with open(label_path, 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) != 5:
                    continue  # Skip if not a valid label line
                cls, x, y, bw, bh = map(float, parts)

                class_id = int(cls) # Convert class to integer

                # Check if class_id is a valid index
                if 0 <= class_id < len(class_names):
                    class_label = class_names[class_id]
                else:
                    # Handle invalid class ID
                    print(f"‚ö†Ô∏è Warning: Invalid class ID {class_id} found in {label_path}")
                    class_label = f"Unknown Class ({class_id})" # Use a placeholder

                x1 = int((x - bw / 2) * w)
                y1 = int((y - bh / 2) * h)
                x2 = int((x + bw / 2) * w)
                y2 = int((y + bh / 2) * h)

                cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)
                cv2.putText(img, class_label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 0), 2)
    else:
        print(f"‚ö†Ô∏è Label file not found for {selected_img}")

    plt.figure(figsize=(8, 8))
    plt.imshow(img)
    plt.title(selected_img)
    plt.axis('off')
    plt.show()

# ‚úÖ Call the function
show_random_labeled_image()

import os

label_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/test/labels"
valid_class_ids = list(range(6))  # 0 to 5 for 6 classes

for filename in os.listdir(label_dir):
    if filename.endswith(".txt"):
        path = os.path.join(label_dir, filename)
        with open(path, "r") as f:
            lines = f.readlines()

        for line in lines:
            if line.strip() == "":
                continue
            cls_id = int(line.strip().split()[0])
            if cls_id not in valid_class_ids:
                print(f"‚ùå Removing: {filename} (invalid class {cls_id})")
                os.remove(path)
                break

"""## ‚úÖ Manual Bounding Box Verification for Specific Image (Accurate and Reliable)
This method loads a specified image and its label file, then correctly draws bounding boxes using YOLO annotations. Confirmed to be accurate for verifying dataset annotations across all images.

"""

import os

dataset_path = "/content/drive/My Drive/Datasets/Acne Detection with YOLOv8"
images_path = os.path.join(dataset_path, "train", "images")
labels_path = os.path.join(dataset_path, "train", "labels")
yaml_path = os.path.join(dataset_path, "data.yaml")  # Path to class names

import yaml

# Load class names from data.yaml
with open(yaml_path, "r") as f:
    data = yaml.safe_load(f)

class_names = data["names"]

# Get the number of classes
num_classes = len(class_names)

# Print the result
print("Number of classes:", num_classes)

import yaml

# Load class names from data.yaml
with open(yaml_path, "r") as f:
    data = yaml.safe_load(f)
class_names = data["names"]

# Print class names to verify
print(" Class names loaded:", class_names)

import cv2
import matplotlib.pyplot as plt

def draw_bounding_boxes(image_path, label_path, class_names):
    # Load image
    image = cv2.imread(image_path)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)  # Convert to RGB format

    # Get image dimensions
    h, w, _ = image.shape

    # Read label file
    if not os.path.exists(label_path):
        print(f" No label file found for {image_path}")
        return

    with open(label_path, "r") as file:
        labels = file.readlines()

    # Loop through each label and draw bounding boxes
    for label in labels:
        data = label.strip().split()
        class_id = int(data[0])  # Get class ID
        x_center, y_center, width, height = map(float, data[1:])  # Get bounding box

        # Convert YOLO format (normalized) to pixel values
        x_center, y_center, width, height = (
            int(x_center * w),
            int(y_center * h),
            int(width * w),
            int(height * h),
        )

        # Get box coordinates
        x1, y1, x2, y2 = (
            x_center - width // 2,
            y_center - height // 2,
            x_center + width // 2,
            y_center + height // 2,
        )

        # Draw bounding box
        color = (255, 0, 0)  # Red box
        cv2.rectangle(image, (x1, y1), (x2, y2), color, 2)

        # Display class name
        class_label = class_names[class_id] if class_id < len(class_names) else f"Class {class_id}"
        cv2.putText(image, class_label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)

    # Show image
    plt.figure(figsize=(8, 8))
    plt.imshow(image)
    plt.axis("off")
    plt.show()

import random

# Get a random image from the dataset
image_files = os.listdir(images_path)
sample_image = random.choice(image_files)  # Select a random image

# Define paths for image and corresponding label file
image_path = os.path.join(images_path, sample_image)
label_path = os.path.join(labels_path, sample_image.replace(".jpg", ".txt"))

# Check if label file exists
if os.path.exists(label_path):
    draw_bounding_boxes(image_path, label_path, class_names)
else:
    print(f"No label found for {sample_image}")

"""# Training the Model

## Installing dependencies
"""

!pip install pillow

!pip install ultralytics

"""## Model Training

## Model 1 - 20 epochs
"""

from ultralytics import YOLO
import os

# ‚úÖ Set dataset and output paths
dataset_path = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8"
output_path = "/content/drive/MyDrive/acne_detection_yolov8"

# ‚úÖ Load model (yolov8m balances accuracy and speed)
model = YOLO("yolov8m.pt")

# ‚úÖ Start training
results = model.train(
    data=os.path.join(dataset_path, "data.yaml"),
    epochs=20,
    imgsz=640,
    batch=8,
    save=True,
    save_period=5,
    project=output_path,
    name="yolov8_finetune",
    device="cuda",       # Automatically uses GPU if available
    workers=4,
    optimizer="AdamW",
    patience=5,
    lr0=0.001,
    momentum=0.9,
    weight_decay=0.0005,
    dropout=0.1
)

print("‚úÖ Training complete!")

from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune7/weights/best.pt")

"""Cleanups the Last pt model"""

import shutil
from pathlib import Path

# ‚úÖ Correct path to your latest run
run_path = Path("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune7")

# Delete unnecessary files like last.pt
to_delete = ['last.pt']
for item in to_delete:
    file_path = run_path / 'weights' / item
    if file_path.exists():
        file_path.unlink()
        print(f"üóëÔ∏è Deleted {item}")
    else:
        print(f"‚ö†Ô∏è {item} not found.")

"""## Model 2 - 30 epochs"""

from ultralytics import YOLO
import os

# ‚úÖ Set dataset and output paths
dataset_path = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8"
output_path = "/content/drive/MyDrive/acne_detection_yolov8"

# ‚úÖ Load pretrained YOLOv8m model
model = YOLO("yolov8m.pt")

# ‚úÖ Start training with stronger generalization & augmentation
results = model.train(
    data=os.path.join(dataset_path, "data.yaml"),  # Path to YAML
    epochs=30,
    imgsz=640,
    batch=16,                     # üîº Increase for Pro GPU to speed up training
    save=True,
    save_period=5,
    project=output_path,
    name="yolov8_finetune_acne2",  # Change name for new run
    device="cuda",

    # Optimization
    optimizer="AdamW",
    lr0=0.001,
    momentum=0.9,
    weight_decay=0.0005,
    dropout=0.1,
    patience=7,

    # üîÅ Augmentation to improve acne detection
    augment=True,
    hsv_h=0.015,
    hsv_s=0.7,
    hsv_v=0.4,
    scale=0.5,
    flipud=0.2,  # vertical flip
    workers=4
)

print("‚úÖ Training complete!")

import shutil
from pathlib import Path

# ‚úÖ Correct path to your latest run
run_path = Path("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne2")

# Delete unnecessary files like last.pt
to_delete = ['last.pt']
for item in to_delete:
    file_path = run_path / 'weights' / item
    if file_path.exists():
        file_path.unlink()
        print(f"üóëÔ∏è Deleted {item}")
    else:
        print(f"‚ö†Ô∏è {item} not found.")

"""## Model 3 - 50 epochs"""

from ultralytics import YOLO

model = YOLO("yolov8m.pt")

model.train(
    data="/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/data.yaml",
    epochs=50,  # More training
    imgsz=640,
    batch=16,
    project="/content/drive/MyDrive/acne_detection_yolov8",
    name="yolov8_finetune_acne3",
    save=True,
    save_period=5,
    device="cuda",
    optimizer="AdamW",
    lr0=0.0007,              # üîΩ Lower LR for finer tuning
    patience=10,             # Allow longer training
    weight_decay=0.0005,
    momentum=0.9,
    dropout=0.1,
    augment=True,
    flipud=0.1,              # üîΩ Reduce vertical flipping
    translate=0.1,
    scale=0.5,
    auto_augment="mix",      # ‚úÖ Use "mix" instead of randaugment for medical data
)
print("‚úÖ Training complete!")

import shutil
from pathlib import Path

# ‚úÖ Correct path to your latest run
run_path = Path("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3")

# Delete unnecessary files like last.pt
to_delete = ['last.pt']
for item in to_delete:
    file_path = run_path / 'weights' / item
    if file_path.exists():
        file_path.unlink()
        print(f"üóëÔ∏è Deleted {item}")
    else:
        print(f"‚ö†Ô∏è {item} not found.")

"""# Testing with Model Predictions

## Trained Model 1
"""

from ultralytics import YOLO

# Load your trained model from the correct path
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune7/weights/best.pt")

import os
import random
import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Load model
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune7/weights/best.pt")

# Pick a random image from test set
test_images_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/test/images"
image_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

if not image_files:
    print("‚ùå No test images found.")
else:
    random_image = random.choice(image_files)
    image_path = os.path.join(test_images_dir, random_image)
    print(f"üéØ Running prediction on: {random_image}")

    # Predict
    results = model.predict(
        source=image_path,
        conf=0.2,
        save=True,
        project="runs/detect",
        name="acne_test_random",
        exist_ok=True  # avoid making new folder each run
    )

    # Get saved image path from results object
    output_path = os.path.join(results[0].save_dir, random_image)

    # Read and display
    img = cv2.imread(str(output_path))
    if img is None:
        print(f"‚ùå Could not read image at {output_path}")
    else:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Extract top prediction
        if results[0].boxes and len(results[0].boxes.cls) > 0:
            pred_class = model.names[int(results[0].boxes.cls[0])]
            pred_conf = float(results[0].boxes.conf[0])
            prediction_label = f"Prediction: {pred_class} ({pred_conf:.2f})"
        else:
            prediction_label = "Prediction: No detection"

        plt.figure(figsize=(8, 8))
        plt.imshow(img)
        plt.axis("off")
        plt.title(prediction_label)
        plt.show()

"""## Trained Model 2"""

from ultralytics import YOLO
import os
import random
import cv2
import matplotlib.pyplot as plt

# ‚úÖ Load the trained model
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne2/weights/best.pt")

# ‚úÖ Path to test images
test_images_path = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images"
image_files = [f for f in os.listdir(test_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

# ‚úÖ Pick a random image
random_image = random.choice(image_files)
image_path = os.path.join(test_images_path, random_image)

# ‚úÖ Run inference
results = model(image_path, conf=0.1, save=False)  # You can adjust conf threshold if needed

# ‚úÖ Extract prediction
result = results[0]
img = cv2.imread(image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

for box in result.boxes:
    cls_id = int(box.cls[0])
    conf = float(box.conf[0])
    label = f"{model.names[cls_id]} {conf:.2f}"

    x1, y1, x2, y2 = map(int, box.xyxy[0])
    color = (0, 255, 0) if conf >= 0.2 else (0, 0, 255)  # ‚úÖ Green for confident, red otherwise
    cv2.rectangle(img, (x1, y1), (x2, y2), color, 2)
    cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)

# ‚úÖ Show result
plt.figure(figsize=(8, 8))
plt.imshow(img)
plt.title(f"Prediction: {label}" if result.boxes else "Prediction: No detection")
plt.axis('off')
plt.show()

"""## Trained Model 3

### conf rate 0.2
"""

!pip install ultralytics

import os
import random
import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Load model
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt")

# Pick a random image from test set
test_images_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/test/images"
image_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

if not image_files:
    print("‚ùå No test images found.")
else:
    random_image = random.choice(image_files)
    image_path = os.path.join(test_images_dir, random_image)
    print(f"üéØ Running prediction on: {random_image}")

    # Predict
    results = model.predict(
        source=image_path,
        conf=0.1,
        save=True,
        project="runs/detect",
        name="acne_test_random",
        exist_ok=True  # avoid making new folder each run
    )

    # Get saved image path from results object
    output_path = os.path.join(results[0].save_dir, random_image)

    # Read and display
    img = cv2.imread(str(output_path))
    if img is None:
        print(f"‚ùå Could not read image at {output_path}")
    else:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Extract top prediction
        if results[0].boxes and len(results[0].boxes.cls) > 0:
            pred_class = model.names[int(results[0].boxes.cls[0])]
            pred_conf = float(results[0].boxes.conf[0])
            prediction_label = f"Prediction: {pred_class} ({pred_conf:.2f})"
        else:
            prediction_label = "Prediction: No detection"

        plt.figure(figsize=(8, 8))
        plt.imshow(img)
        plt.axis("off")
        plt.title(prediction_label)
        plt.show()

"""### conf rate 0.4"""

import os
import random
import cv2
import matplotlib.pyplot as plt
from ultralytics import YOLO

# Load model
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt")

# Pick a random image from test set
test_images_dir = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/test/images"
image_files = [f for f in os.listdir(test_images_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]

if not image_files:
    print("‚ùå No test images found.")
else:
    random_image = random.choice(image_files)
    image_path = os.path.join(test_images_dir, random_image)
    print(f"üéØ Running prediction on: {random_image}")

    # Predict
    results = model.predict(
        source=image_path,
        conf=0.1,
        save=True,
        project="runs/detect",
        name="acne_test_random",
        exist_ok=True  # avoid making new folder each run
    )

    # Get saved image path from results object
    output_path = os.path.join(results[0].save_dir, random_image)

    # Read and display
    img = cv2.imread(str(output_path))
    if img is None:
        print(f"‚ùå Could not read image at {output_path}")
    else:
        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

        # Extract top prediction
        if results[0].boxes and len(results[0].boxes.cls) > 0:
            pred_class = model.names[int(results[0].boxes.cls[0])]
            pred_conf = float(results[0].boxes.conf[0])
            prediction_label = f"Prediction: {pred_class} ({pred_conf:.2f})"
        else:
            prediction_label = "Prediction: No detection"

        plt.figure(figsize=(8, 8))
        plt.imshow(img)
        plt.axis("off")
        plt.title(prediction_label)
        plt.show()

"""### conf rate 0.3"""

from ultralytics import YOLO
import os
import random
import cv2
import matplotlib.pyplot as plt

# ‚úÖ Load the trained model
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt")

# ‚úÖ Path to test images
test_images_path = "/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images"
image_files = [f for f in os.listdir(test_images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]

# ‚úÖ Pick a random image
random_image = random.choice(image_files)
image_path = os.path.join(test_images_path, random_image)

# ‚úÖ Run inference with conf threshold = 0.3
results = model(image_path, conf=0.3, save=False)

# ‚úÖ Extract prediction
result = results[0]
img = cv2.imread(image_path)
img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)

# ‚úÖ Draw boxes and show predicted classes
if result.boxes:
    for box in result.boxes:
        cls_id = int(box.cls[0])
        conf = float(box.conf[0])
        label = f"{model.names[cls_id]} {conf:.2f}"

        x1, y1, x2, y2 = map(int, box.xyxy[0])
        cv2.rectangle(img, (x1, y1), (x2, y2), (255, 0, 255), 2)
        cv2.putText(img, label, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 0, 255), 2)

    plt.title(f"Prediction: {label}")
else:
    plt.title("Prediction: No detection")

# ‚úÖ Show result
plt.figure(figsize=(8, 8))
plt.imshow(img)
plt.axis('off')
plt.show()

"""# Fine Tune the Model 3 best.pt

Loading the model

## Model Fine tune training
"""

from ultralytics import YOLO

model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt")

model.train(
    data="/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/data.yaml",
    epochs=30,                      # ‚è≥ Continue training
    imgsz=640,
    batch=16,
    project="/content/drive/MyDrive/acne_detection_yolov8",
    name="yolov8_finetune_acne3_v1",  # üîÅ New folder for continued training
    save=True,
    save_period=5,
    device="cuda",
    optimizer="AdamW",
    lr0=0.0005,                     # üîΩ Slightly lower LR
    patience=15,                    # üß† Let early stopping work well
    dropout=0.1,
    momentum=0.9,
    weight_decay=0.0005,
    augment=True,
    translate=0.1,
    flipud=0.1,
    scale=0.5,
    auto_augment="mix"
)

"""## Model Testing with Random Images"""

from ultralytics import YOLO
model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3_v1/weights/best.pt")

# STEP 1: Install dependencies
!pip install ultralytics opencv-python matplotlib --quiet

# STEP 2: Import necessary packages
from ultralytics import YOLO
import cv2
import matplotlib.pyplot as plt
import random
import os

# STEP 3: Load fine-tuned model (adjust name if different)
model = YOLO('/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt')

# STEP 4: Set your image folder
image_folder = '/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images'
image_files = os.listdir(image_folder)
random_image = random.choice(image_files)
image_path = os.path.join(image_folder, random_image)

# STEP 5: Run prediction
results = model(image_path)

# STEP 6: Draw predictions manually using OpenCV
image = cv2.imread(image_path)
image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

for r in results:
    for box in r.boxes:
        cls = int(box.cls[0])
        conf = float(box.conf[0])
        label = model.names[cls]
        x1, y1, x2, y2 = map(int, box.xyxy[0])

        # Draw bounding box and label
        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, f'{label} ({conf:.2f})', (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)

# STEP 7: Display the image with heading
plt.figure(figsize=(8, 6))
plt.imshow(image)
plt.axis('off')
plt.title("Detected Acne", fontsize=16, weight='bold')
plt.show()

from ultralytics import YOLO
from PIL import Image
from IPython.display import display
import os
import random
import glob
import cv2
import matplotlib.pyplot as plt

# STEP 1: Load the trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3_v1/weights/best.pt')

# STEP 2: Define the image folder
image_folder = '/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images'

# STEP 3: Get all images from the folder
image_extensions = ['*.jpg', '*.jpeg', '*.png']
image_files = []
for ext in image_extensions:
    image_files.extend(glob.glob(os.path.join(image_folder, ext)))

# STEP 4: Pick a random image
if image_files:
    selected_image = random.choice(image_files)
    print(f"üì∏ Selected Random Image: {selected_image}")
else:
    print("‚ùå No images found!")
    selected_image = None

# STEP 5: Run detection and show results
if selected_image:
    results = model.predict(source=selected_image, imgsz=640, conf=0.1, save=False)

    # Load image for visualization
    image = cv2.imread(selected_image)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Check and print detections
    if not results[0].boxes or len(results[0].boxes) == 0:
        print("‚ùå No acne detected in this image.")
    else:
        print("\nüîç **Detection Results:**")
        for box in results[0].boxes:
            class_id = int(box.cls[0])
            confidence = float(box.conf[0])
            bbox = [round(i, 2) for i in box.xyxy[0].tolist()]
            acne_class = model.names[class_id]

            print(f"‚úÖ Detected Acne: {acne_class} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")

            # Draw bounding box
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, f"{acne_class} ({confidence:.2f})", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Show final result
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    plt.axis("off")
    plt.title("Detected Acne")
    plt.show()

from ultralytics import YOLO
from PIL import Image
from IPython.display import display
import os
import random
import glob
import cv2
import matplotlib.pyplot as plt

# STEP 1: Load the trained YOLOv8 model
model = YOLO('/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt')

# STEP 2: Define the image folder
image_folder = '/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images'

# STEP 3: Get all images from the folder
image_extensions = ['*.jpg', '*.jpeg', '*.png']
image_files = []
for ext in image_extensions:
    image_files.extend(glob.glob(os.path.join(image_folder, ext)))

# STEP 4: Pick a random image
if image_files:
    selected_image = random.choice(image_files)
    print(f"üì∏ Selected Random Image: {selected_image}")
else:
    print("‚ùå No images found!")
    selected_image = None

# STEP 5: Run detection and show results
if selected_image:
    results = model.predict(source=selected_image, imgsz=640, conf=0.1, save=False)

    # Load image for visualization
    image = cv2.imread(selected_image)
    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    # Check and print detections
    if not results[0].boxes or len(results[0].boxes) == 0:
        print("‚ùå No acne detected in this image.")
    else:
        print("\nüîç **Detection Results:**")
        for box in results[0].boxes:
            class_id = int(box.cls[0])
            confidence = float(box.conf[0])
            bbox = [round(i, 2) for i in box.xyxy[0].tolist()]
            acne_class = model.names[class_id]

            print(f"‚úÖ Detected Acne: {acne_class} | Confidence: {confidence:.2f} | Bounding Box: {bbox}")

            # Draw bounding box
            x1, y1, x2, y2 = map(int, bbox)
            cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
            cv2.putText(image, f"{acne_class} ({confidence:.2f})", (x1, y1 - 10),
                        cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    # Show final result
    plt.figure(figsize=(10, 10))
    plt.imshow(image)
    plt.axis("off")
    plt.title("Detected Acne")
    plt.show()

"""# CNN Model Trainning

## Python Script to Crop Images (Acne Type Only)
"""

from google.colab import drive
drive.mount('/content/drive')

import os
import cv2

# === Setup your paths ===
images_path = '/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/images'
labels_path = '/content/drive/MyDrive/Datasets/Acne Detection with YOLOv8/train/labels'
output_dir = '/content/drive/MyDrive/cnn_dataset'  # This will be created in Colab or Drive

# === Full YOLO class names (18 combined classes)
class_names_raw = [
    'Blackheads_Mild', 'Blackheads_Moderate', 'Blackheads_Severe',
    'Cystic_Mild', 'Cystic_Moderate', 'Cystic_Severe',
    'Nodular_Mild', 'Nodular_Moderate', 'Nodular_Severe',
    'Papules_Mild', 'Papules_Moderate', 'Papules_Severe',
    'Pustules_Mild', 'Pustules_Moderate', 'Pustules_Severe',
    'Whiteheads_Mild', 'Whiteheads_Moderate', 'Whiteheads_Severe'
]

# Extract only type from each class name and deduplicate
acne_types = sorted(list(set([c.split('_')[0].lower() for c in class_names_raw])))

# Create output folders by type
for acne_type in acne_types:
    os.makedirs(os.path.join(output_dir, acne_type), exist_ok=True)

# Begin cropping
for label_file in os.listdir(labels_path):
    if not label_file.endswith('.txt'):
        continue

    image_file = label_file.replace('.txt', '.jpg')
    img_path = os.path.join(images_path, image_file)
    label_path = os.path.join(labels_path, label_file)

    if not os.path.exists(img_path):
        continue

    image = cv2.imread(img_path)
    h, w, _ = image.shape

    with open(label_path, 'r') as f:
        for idx, line in enumerate(f.readlines()):
            class_id, x_center, y_center, width, height = map(float, line.strip().split())
            full_class = class_names_raw[int(class_id)]
            acne_type = full_class.split('_')[0].lower()  # e.g., "Blackheads_Mild" ‚Üí "blackheads"

            # Convert YOLO bbox to pixel coords
            x1 = int((x_center - width / 2) * w)
            y1 = int((y_center - height / 2) * h)
            x2 = int((x_center + width / 2) * w)
            y2 = int((y_center + height / 2) * h)

            # Crop
            crop = image[y1:y2, x1:x2]
            if crop.size == 0:
                continue

            save_path = os.path.join(output_dir, acne_type, f"{label_file[:-4]}_{idx}.jpg")
            cv2.imwrite(save_path, crop)

import os

# Path to your CNN dataset
cnn_dataset_path = '/content/drive/MyDrive/cnn_dataset'

# List all class folders and count images
print("üìÅ CNN Dataset Overview:\n")
for class_name in sorted(os.listdir(cnn_dataset_path)):
    class_path = os.path.join(cnn_dataset_path, class_name)
    if os.path.isdir(class_path):
        image_count = len([f for f in os.listdir(class_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])
        print(f"üî∏ {class_name}: {image_count} images")

"""## Load Dataset in Colab"""

pip install tensorflow

import tensorflow as tf
from tensorflow.keras.preprocessing import image_dataset_from_directory

# === Step 1: Load Dataset ===
print("üì• Loading CNN dataset from folders...")
cnn_dataset_path = '/content/drive/MyDrive/cnn_dataset'
img_size = (128, 128)
batch_size = 32

train_ds = image_dataset_from_directory(
    cnn_dataset_path,
    validation_split=0.2,
    subset="training",
    seed=42,
    image_size=img_size,
    batch_size=batch_size,
    label_mode='categorical'
)

val_ds = image_dataset_from_directory(
    cnn_dataset_path,
    validation_split=0.2,
    subset="validation",
    seed=42,
    image_size=img_size,
    batch_size=batch_size,
    label_mode='categorical'
)

print(f"‚úÖ Dataset loaded successfully.")
print(f"üî∏ Classes: {train_ds.class_names}")
print(f"üîπ Training batches: {len(train_ds)}")
print(f"üîπ Validation batches: {len(val_ds)}")

"""## Build the CNN Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

# === Step 2: Build CNN Model ===
print("\n Building the CNN model...")
model = Sequential([
    Conv2D(32, (3, 3), activation='relu', input_shape=(128, 128, 3)),
    MaxPooling2D(2, 2),

    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),

    Flatten(),
    Dense(128, activation='relu'),
    Dropout(0.3),
    Dense(6, activation='softmax')  # 6 acne types
])
print("‚úÖ Model built.")

"""## Compile & Train Model"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout

print("\n Compiling and training the model...")
model.compile(optimizer='adam',
              loss='categorical_crossentropy',
              metrics=['accuracy'])

history = model.fit(train_ds, validation_data=val_ds, epochs=10)
print("‚úÖ Model training completed.")

# === Step 4: Save the Model ===
# model.save('/content/drive/MyDrive/cnn_acne_model.h5')
model.save("/content/drive/MyDrive/cnn_acne_model.keras")
print(" Model saved as cnn_acne_model.keras")

"""## Plot Accuracy and Analysis"""

import matplotlib.pyplot as plt
# === Step 5: Plot Accuracy and Loss ===
print("\nüìà Plotting accuracy and loss graphs...")

# Accuracy
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Val Accuracy')
plt.title('Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# Loss
plt.plot(history.history['loss'], label='Train Loss')
plt.plot(history.history['val_loss'], label='Val Loss')
plt.title('Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()

print("‚úÖ Training analysis visualized.")

"""## Fine tuning the Model with 5 epochs

"""

from tensorflow.keras.models import load_model

model = load_model('/content/drive/MyDrive/cnn_acne_model.keras')  # or .keras
print("‚úÖ Model loaded for fine-tuning.")

"""### Compile with lower learning rate"""

from tensorflow.keras.optimizers import Adam

model.compile(
    optimizer=Adam(learning_rate=1e-4),  # slower learning
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping

# Define Early Stopping callback
early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

fine_tune_history = model.fit(
    train_ds,
    validation_data=val_ds,
    epochs=5,  # just a few more
    callbacks=[early_stop]
)

model.save('/content/drive/MyDrive/cnn_acne_model_finetuned.keras')

import matplotlib.pyplot as plt

# === Accuracy Plot ===
plt.figure(figsize=(10, 4))
plt.plot(fine_tune_history.history['accuracy'], label='Train Accuracy')
plt.plot(fine_tune_history.history['val_accuracy'], label='Val Accuracy')
plt.title('üìà Fine-tuned Model Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.grid(True)
plt.show()

# === Loss Plot ===
plt.figure(figsize=(10, 4))
plt.plot(fine_tune_history.history['loss'], label='Train Loss')
plt.plot(fine_tune_history.history['val_loss'], label='Val Loss')
plt.title('üìâ Fine-tuned Model Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.grid(True)
plt.show()


print("‚úÖ Training analysis visualized.")

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, auc
from sklearn.preprocessing import label_binarize
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import os

# === Load the trained CNN model ===
sequential_model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# === Define dataset path and parameters ===
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
img_size = (128, 128)  # change if you used a different input size
batch_size = 32

# === Load test data using ImageDataGenerator ===
test_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)

test_generator = test_datagen.flow_from_directory(
    cnn_dataset_path,
    target_size=img_size,
    batch_size=batch_size,
    class_mode='categorical',
    shuffle=False,
    subset='validation'
)

# === Get true labels and predictions ===
y_true = test_generator.classes
y_true_binarized = label_binarize(y_true, classes=range(test_generator.num_classes))

y_pred_probs = sequential_model.predict(test_generator)
class_names = list(test_generator.class_indices.keys())

# === Plot ROC curve for each class ===
fpr = dict()
tpr = dict()
roc_auc = dict()

for i in range(test_generator.num_classes):
    fpr[i], tpr[i], _ = roc_curve(y_true_binarized[:, i], y_pred_probs[:, i])
    roc_auc[i] = auc(fpr[i], tpr[i])

# === Plot all ROC curves ===
plt.figure(figsize=(10, 8))
for i in range(test_generator.num_classes):
    plt.plot(fpr[i], tpr[i], label=f"Class {class_names[i]} (AUC = {roc_auc[i]:.2f})")

plt.plot([0, 1], [0, 1], 'k--')  # diagonal line
plt.xlabel("False Positive Rate")
plt.ylabel("True Positive Rate")
plt.title("ROC Curves for CNN Model")
plt.legend(loc="lower right")
plt.grid(True)
plt.show()

"""# Grad-CAM Application for the Custom CNN model

## Gradcam Testing 1
"""

import os
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Path to your CNN dataset (change if needed)
cnn_dataset_path = "/content/drive/MyDrive/cnn_dataset"

# Get a random class folder
class_folder = random.choice(os.listdir(cnn_dataset_path))
class_path = os.path.join(cnn_dataset_path, class_folder)

# Get a random image from that class
image_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, image_name)

# Load and preprocess the image
img = cv2.imread(img_path)
img_resized = cv2.resize(img, (128, 128))  # CNN input size
img_array = np.expand_dims(img_resized / 255.0, axis=0)

# Show the image and label
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.title(f"Random Test Image: {class_folder}")
plt.axis('off')
plt.show()

# === Step 4: Make a dummy prediction to "build" the model ===
_ = model.predict(img_array)

# === Step 5: Grad-CAM helper ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # Get the convolutional layer
    last_conv_layer = model.get_layer(name=last_conv_layer_name)

    # Create a sub-model that maps input -> last conv layer output + final output
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[last_conv_layer.output, model.output]
    )

    # Watch the conv layer and calculate gradients
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        output_class = predictions[:, pred_index]

    # Gradients of the class output w.r.t. conv output
    grads = tape.gradient(output_class, conv_outputs)

    # Mean of the gradients
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Multiply each channel by the mean gradients
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)

    # Normalize the heatmap
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)
    return heatmap.numpy()

# === Step 6: Generate Grad-CAM ===
last_conv_layer_name = "conv2d_2"  # Update if needed
_ = model.predict(img_array)

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)

# === Step 7: Overlay heatmap ===
def overlay_heatmap(img_orig, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    heatmap = cv2.resize(heatmap, (img_orig.shape[1], img_orig.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap_color = cv2.applyColorMap(heatmap, colormap)
    overlayed = cv2.addWeighted(img_orig, 1 - alpha, heatmap_color, alpha, 0)
    return overlayed

# === Step 8: Show final result ===
# Use img_resized (your original resized BGR image)
overlayed_img = overlay_heatmap(img_resized, heatmap)

plt.imshow(cv2.cvtColor(overlayed_img, cv2.COLOR_BGR2RGB))
plt.title(f"Grad-CAM: {class_folder}")
plt.axis('off')
plt.show()

"""## Gradcam Testing 2"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Step 1: Load and build the model ===
model = tf.keras.models.load_model("/content/drive/MyDrive/cnn_acne_model.keras")

# === Step 2: Load a sample image ===
cnn_dataset_path = "/content/drive/MyDrive/cnn_dataset"
class_folder = random.choice(os.listdir(cnn_dataset_path))
class_path = os.path.join(cnn_dataset_path, class_folder)
image_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, image_name)

img = cv2.imread(img_path)
img_resized = cv2.resize(img, (128, 128))
img_array = np.expand_dims(img_resized / 255.0, axis=0)

# === Step 3: Force model to run once (required for Grad-CAM to work) ===
# ‚úÖ Properly define input/output by wrapping the sequential model
inputs = tf.keras.Input(shape=(128, 128, 3))
outputs = model(inputs)
model = tf.keras.Model(inputs, outputs)

# === Step 4: Grad-CAM function ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    last_conv_layer = model.get_layer(name=last_conv_layer_name)
    grad_model = tf.keras.models.Model(
        [model.input], [last_conv_layer.output, model.output]
    )

    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        class_channel = predictions[:, pred_index]

    grads = tape.gradient(class_channel, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = conv_outputs @ pooled_grads[..., tf.newaxis]
    heatmap = tf.squeeze(heatmap)
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)
    return heatmap.numpy()

# === Step 5: Generate Grad-CAM heatmap ===
last_conv_layer_name = "conv2d_2"
heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)

# === Step 6: Overlay heatmap ===
def overlay_heatmap(img_orig, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    heatmap = cv2.resize(heatmap, (img_orig.shape[1], img_orig.shape[0]))
    heatmap = np.uint8(255 * heatmap)
    heatmap_color = cv2.applyColorMap(heatmap, colormap)
    overlayed = cv2.addWeighted(img_orig, 1 - alpha, heatmap_color, alpha, 0)
    return overlayed

overlayed_img = overlay_heatmap(img_resized, heatmap)

# === Step 7: Display result ===
plt.imshow(cv2.cvtColor(overlayed_img, cv2.COLOR_BGR2RGB))
plt.title(f"Grad-CAM: {class_folder}")
plt.axis('off')
plt.show()

"""## GradCam Testing 3"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Step 1: Load the model ===
# Loading the model creates the architecture but might not define input/output shapes immediately
model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# === Step 2: Load a sample image ===
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
# Check if the directory exists and is not empty
if not os.path.exists(cnn_dataset_path) or not os.listdir(cnn_dataset_path):
    raise FileNotFoundError(f"CNN dataset path not found or empty: {cnn_dataset_path}")

class_folder = random.choice(os.listdir(cnn_dataset_path))
class_path = os.path.join(cnn_dataset_path, class_folder)

# Check if the class folder exists and is not empty
if not os.path.exists(class_path) or not os.listdir(class_path):
     raise FileNotFoundError(f"Class folder not found or empty: {class_path}")

image_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, image_name)

# Check if the image file exists
if not os.path.exists(img_path):
    raise FileNotFoundError(f"Image file not found: {img_path}")

img = cv2.imread(img_path)
if img is None:
    raise IOError(f"Failed to load image: {img_path}")

img_resized = cv2.resize(img, (128, 128))
img_array = np.expand_dims(img_resized / 255.0, axis=0)

# === Step 3: Force model to run once (required for Grad-CAM to work) ===
# This step builds the model by passing data through it,
# making the .input and .output attributes available.
# ‚úÖ Properly define input/output by wrapping the sequential model
inputs = tf.keras.Input(shape=(128, 128, 3))
outputs = model(inputs)
model = tf.keras.Model(inputs, outputs) # Moved this line BEFORE calling make_gradcam_heatmap

# === Step 4: Grad-CAM function ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):
    # Ensure the layer name exists in the model
    try:
        last_conv_layer = model.get_layer(name=last_conv_layer_name)
    except ValueError:
        print(f"‚ùå Error: Layer with name '{last_conv_layer_name}' not found in the model.")
        print("Available layers:", [layer.name for layer in model.layers])
        return None # Return None to indicate failure

    # Create a sub-model that maps input -> last conv layer output + final output
    # model.input and model.output are now defined because model(img_array) was called
    grad_model = tf.keras.models.Model(
        [model.input], [last_conv_layer.output, model.output]
    )

    # Watch the conv layer and calculate gradients
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_array)
        if pred_index is None:
            # Handle case where model has no predictions or incorrect shape
            if predictions is None or predictions.shape[1] == 0:
                 print("‚ö†Ô∏è Warning: Model predictions are empty or have invalid shape. Cannot determine pred_index.")
                 return None
            pred_index = tf.argmax(predictions[0])
        output_class = predictions[:, pred_index]

    # Gradients of the class output w.r.t. conv output
    grads = tape.gradient(output_class, conv_outputs)

    # Mean of the gradients across spatial dimensions
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Multiply each channel in the conv output by the corresponding mean gradient
    # and sum the results to get the heatmap for that location
    conv_outputs = conv_outputs[0] # Remove batch dimension
    # This is a weighted sum of the feature map channels
    heatmap = tf.einsum('ij,j->i', tf.reshape(conv_outputs, [-1, tf.shape(conv_outputs)[-1]]), pooled_grads)
    heatmap = tf.reshape(heatmap, tf.shape(conv_outputs)[0:2]) # Reshape back to 2D

    # Normalize the heatmap
    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap + 1e-10)
    return heatmap.numpy()

# === Step 5: Generate Grad-CAM heatmap ===
# You might need to inspect your model's layers to get the correct name
# print([layer.name for layer in model.layers]) # Uncomment to see layer names
last_conv_layer_name = "conv2d_2" # Assuming this is still the correct last conv layer name

# Check if the layer name is correct
try:
    model.get_layer(name=last_conv_layer_name)
except ValueError:
     print(f"‚ùå Error: Layer with name '{last_conv_layer_name}' not found in the model.")
     print("Available layers:", [layer.name for layer in model.layers])
     # You should update last_conv_layer_name based on the output if necessary
     # For example, if the last conv layer is named 'conv2d_3'
     # last_conv_layer_name = 'conv2d_3'
     # Then call the make_gradcam_heatmap function again


heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)

# === Step 6: Overlay heatmap ===
def overlay_heatmap(img_orig, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    # Ensure heatmap generation was successful
    if heatmap is None:
        print("‚ùå Cannot overlay heatmap as heatmap generation failed.")
        return cv2.cvtColor(img_orig, cv2.COLOR_BGR2RGB) # Return original image

    # Resize heatmap to original image dimensions
    heatmap_resized = cv2.resize(heatmap, (img_orig.shape[1], img_orig.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized) # Scale to 0-255
    heatmap_color = cv2.applyColorMap(heatmap_normalized, colormap) # Apply colormap

    # Overlay the heatmap on the original image
    # Ensure img_orig is in BGR format for cv2.addWeighted
    overlayed = cv2.addWeighted(img_orig, 1 - alpha, heatmap_color, alpha, 0)
    return overlayed

# === Step 7: Display result ===
# img_resized is the image resized to 128x128
# img is the original image loaded by cv2.imread (likely in BGR format)
# The overlay_heatmap function should take the original image (img) for correct resizing
# and also needs the original image to be in BGR format as expected by cv2.addWeighted

# Convert img to RGB for displaying with matplotlib later, but keep img_resized in BGR
# for the overlay_heatmap function if it expects BGR input.
# Let's pass the *original* image (img) to overlay_heatmap after converting it to RGB for display.
# Or better, pass img_resized if you want the heatmap overlaid on the resized image,
# but convert it back to BGR before passing to overlay_heatmap if that function expects BGR.

# Let's modify overlay_heatmap to expect RGB input and handle the conversion internally
def overlay_heatmap(img_orig_rgb, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    if heatmap is None:
         print("‚ùå Cannot overlay heatmap as heatmap generation failed.")
         return img_orig_rgb # Return original RGB image

    # Convert input image to BGR for cv2 operations
    img_orig_bgr = cv2.cvtColor(img_orig_rgb, cv2.COLOR_RGB2BGR)

    heatmap_resized = cv2.resize(heatmap, (img_orig_bgr.shape[1], img_orig_bgr.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized)
    heatmap_color = cv2.applyColorMap(heatmap_normalized, colormap)

    overlayed_bgr = cv2.addWeighted(img_orig_bgr, 1 - alpha, heatmap_color, alpha, 0)

    # Convert back to RGB for matplotlib display
    overlayed_rgb = cv2.cvtColor(overlayed_bgr, cv2.COLOR_BGR2RGB)
    return overlayed_rgb

# Convert img_resized to RGB before passing to the (modified) overlay_heatmap function
overlayed_img_rgb = overlay_heatmap(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB), heatmap)


plt.imshow(overlayed_img_rgb) # Display the RGB image
plt.title(f"Grad-CAM: {class_folder}")
plt.axis('off')
plt.show()

"""## Checking the Layers insdie the CNN"""

# Show layers inside the actual CNN (Sequential part)
for layer in model.get_layer('sequential').layers:
    print(layer.name)

"""## GradCam Testing 4"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Step 1: Load the model ===
# Loading the model creates the architecture but might not define input/output shapes immediately
model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# Wrap the Sequential model properly so .input and .output are defined
# Pass a dummy input through the model to build it if it hasn't been already
dummy_input = tf.zeros((1, 128, 128, 3))
_ = model(dummy_input)


# Now, model.input and model.output should be defined
# If the original model was Sequential, wrap it explicitly as a Functional model
# This makes accessing layers and input/output reliable
if isinstance(model, tf.keras.Sequential):
    inputs = tf.keras.Input(shape=(128, 128, 3))
    outputs = model(inputs)
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    print("‚úÖ Wrapped Sequential model as Functional model.")
else:
    print("‚úÖ Model is already a Functional model.")


# === Step 2: Load a sample image ===
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
# Check if the directory exists and is not empty
if not os.path.exists(cnn_dataset_path) or not os.listdir(cnn_dataset_path):
    raise FileNotFoundError(f"CNN dataset path not found or empty: {cnn_dataset_path}")

class_folder = random.choice(os.listdir(cnn_dataset_path))
class_path = os.path.join(cnn_dataset_path, class_folder)

# Check if the class folder exists and is not empty
if not os.path.exists(class_path) or not os.listdir(class_path):
     raise FileNotFoundError(f"Class folder not found or empty: {class_path}")

image_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, image_name)

# Check if the image file exists
if not os.path.exists(img_path):
    raise FileNotFoundError(f"Image file not found: {img_path}")

img = cv2.imread(img_path)
if img is None:
    raise IOError(f"Failed to load image: {img_path}")

img_resized = cv2.resize(img, (128, 128))
img_array = np.expand_dims(img_resized / 255.0, axis=0)

# === Step 3: Grad-CAM Function ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2", pred_index=None):
    # Ensure the layer name exists in the model.
    # If the model was originally Sequential and wrapped, the layers are inside 'sequential'.
    # We need to check both the main model and the 'sequential' sub-model.
    last_conv_layer = None
    try:
        last_conv_layer = model.get_layer(name=last_conv_layer_name)
    except ValueError:
        # Layer not found directly, check inside the 'sequential' layer
        try:
            sequential_layer = model.get_layer('sequential')
            last_conv_layer = sequential_layer.get_layer(last_conv_layer_name)
            print(f"‚úÖ Found layer '{last_conv_layer_name}' inside 'sequential'.")
        except ValueError:
            print(f"‚ùå Error: Layer with name '{last_conv_layer_name}' not found in the model or inside 'sequential'.")
            print("Available layers in main model:", [layer.name for layer in model.layers])
            try:
                 print("Available layers in 'sequential':", [layer.name for layer in sequential_layer.layers])
            except:
                 pass # 'sequential' layer might not exist or not have layers
            return None # Return None to indicate failure

    # Create a sub-model that maps input -> last conv layer output + final output
    # model.input and model.output should be defined here
    try:
        grad_model = tf.keras.models.Model(
            inputs=model.input,
            outputs=[last_conv_layer.output, model.output]
        )
    except Exception as e:
        print(f"‚ùå Error creating grad_model: {e}")
        # Optional: Print model summary to debug inputs/outputs
        # model.summary()
        return None


   try:
    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_tensor)
        if predictions is None or predictions.shape[1] == 0:
            print("‚ö†Ô∏è Warning: Model predictions are empty or have invalid shape.")
            return None
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        output_class = predictions[:, pred_index]
except Exception as e:
    print(f"‚ùå Error calling grad_model: {e}")
    print("Input shape to grad_model:", img_array.shape)
    return None



        if pred_index is None:
            # Get the index of the predicted class
            pred_index = tf.argmax(predictions[0])

        # Calculate the gradient of the predicted class score with respect to the output of the last convolutional layer
        output_class = predictions[:, pred_index]


    grads = tape.gradient(output_class, conv_outputs)

    # Mean of the gradients across spatial dimensions (height and width)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Multiply each channel in the conv output by the corresponding mean gradient
    # and sum the results to get the heatmap for that location.
    # This operation effectively highlights the regions in the convolutional feature maps
    # that were most influential in predicting the target class.
    # conv_outputs = conv_outputs[0] # Remove batch dimension
    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)
    conv_outputs, predictions = grad_model(img_tensor)


    # Perform the weighted sum of the feature map channels
    # Reshape conv_outputs from (height, width, channels) to (height * width, channels)
    # and pooled_grads from (channels,) to (channels, 1) or equivalent for matrix multiplication
    # The einsum operation 'ij,j->i' performs this weighted sum:
    # For each spatial location (i in 'ij'), multiply its channel values (j in 'ij')
    # by the corresponding pooled gradient (j in 'j->i'), and sum over j.
    # The result is a 1D array (i in 'ij,j->i') where each element is the Grad-CAM value
    # for a specific spatial location in the original convolutional output.
    try:
        heatmap = tf.einsum('ij,j->i', tf.reshape(conv_outputs, [-1, tf.shape(conv_outputs)[-1]]), pooled_grads)
        # Reshape the 1D heatmap back to the original spatial dimensions of the conv output
        heatmap = tf.reshape(heatmap, tf.shape(conv_outputs)[0:2])
    except Exception as e:
         print(f"‚ùå Error during heatmap calculation (einsum/reshape): {e}")
         return None


    # Apply ReLU to the heatmap to keep only positive influences and normalize
    # Add a small epsilon (1e-10) to the denominator to prevent division by zero if max is zero
    heatmap = tf.maximum(heatmap, 0) / (tf.math.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

# === Step 4: Generate heatmap ===
# You might need to inspect your model's layers to get the correct name
# print([layer.name for layer in model.layers]) # Uncomment to see main model layer names
# print([layer.name for layer in model.get_layer('sequential').layers]) # Uncomment to see Sequential layer names

# Assuming 'conv2d_2' is indeed the name of the last convolutional layer within the Sequential block
last_conv_layer_name_to_use = "conv2d_2"

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name=last_conv_layer_name_to_use)

# === Step 5: Overlay Heatmap ===
def overlay_heatmap(img_rgb, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    if heatmap is None:
        print("‚ö†Ô∏è Cannot overlay heatmap ‚Äî heatmap generation failed.")
        return img_rgb # Return original RGB image

    # Convert input image to BGR for cv2 operations
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    # Resize heatmap to match the dimensions of the *input* image to this function (img_rgb/img_bgr)
    heatmap_resized = cv2.resize(heatmap, (img_bgr.shape[1], img_bgr.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized) # Scale to 0-255
    heatmap_color = cv2.applyColorMap(heatmap_normalized, colormap) # Apply colormap

    # Overlay the heatmap on the original image (in BGR format)
    overlayed_bgr = cv2.addWeighted(img_bgr, 1 - alpha, heatmap_color, alpha, 0)

    # Convert back to RGB for matplotlib display
    overlayed_rgb = cv2.cvtColor(overlayed_bgr, cv2.COLOR_BGR2RGB)
    return overlayed_rgb

# === Step 6: Display ===
# Pass the resized image (converted to RGB) to the overlay function
if heatmap is not None: # Only attempt to overlay if heatmap was successfully generated
    overlayed_img = overlay_heatmap(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB), heatmap)
    plt.imshow(overlayed_img)
    plt.title(f"Grad-CAM: {class_folder}")
    plt.axis('off')
    plt.show()
else:
    print("‚ùå Grad-CAM heatmap generation failed. Displaying original resized image.")
    plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))
    plt.title(f"Original Resized Image: {class_folder}")
    plt.axis('off')
    plt.show()

"""## GradCam Testing 5"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Step 1: Load the model ===
model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")
_ = model(tf.zeros((1, 128, 128, 3)))  # Build the model

# Wrap Sequential model as Functional if needed
if isinstance(model, tf.keras.Sequential):
    inputs = tf.keras.Input(shape=(128, 128, 3))
    outputs = model(inputs)
    model = tf.keras.Model(inputs, outputs)
    print("‚úÖ Wrapped Sequential model as Functional model.")

# === Step 2: Load random test image ===
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
class_folder = random.choice(os.listdir(cnn_dataset_path))
class_path = os.path.join(cnn_dataset_path, class_folder)
image_name = random.choice(os.listdir(class_path))
img_path = os.path.join(class_path, image_name)

img = cv2.imread(img_path)
img_resized = cv2.resize(img, (128, 128))
img_array = np.expand_dims(img_resized / 255.0, axis=0)

# === Step 3: Grad-CAM Function ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2", pred_index=None):
    try:
        last_conv_layer = model.get_layer(name=last_conv_layer_name)
    except ValueError:
        try:
            last_conv_layer = model.get_layer("sequential").get_layer(last_conv_layer_name)
            print(f"‚úÖ Found '{last_conv_layer_name}' inside 'sequential'.")
        except:
            print("‚ùå Couldn't find the convolutional layer.")
            return None

    # Build grad_model
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[last_conv_layer.output, model.output]
    )

    # Track gradients
    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)
    with tf.GradientTape() as tape:
        conv_outputs, predictions = grad_model(img_tensor)
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])
        output_class = predictions[:, pred_index]

    # Compute gradients
    grads = tape.gradient(output_class, conv_outputs)
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)

    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

# === Step 4: Generate Grad-CAM ===
heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2")

# === Step 5: Overlay heatmap on image ===
def overlay_heatmap(img_rgb, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    if heatmap is None:
        print("‚ö†Ô∏è Heatmap generation failed.")
        return img_rgb

    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)
    heatmap_resized = cv2.resize(heatmap, (img_bgr.shape[1], img_bgr.shape[0]))
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap_resized), colormap)
    overlayed_bgr = cv2.addWeighted(img_bgr, 1 - alpha, heatmap_color, alpha, 0)
    return cv2.cvtColor(overlayed_bgr, cv2.COLOR_BGR2RGB)

# === Step 6: Display ===
if heatmap is not None:
    overlayed_img = overlay_heatmap(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB), heatmap)
    plt.imshow(overlayed_img)
    plt.title(f"Grad-CAM: {class_folder}")
else:
    plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))
    plt.title(f"Original Image: {class_folder}")
plt.axis('off')
plt.show()

"""## GradCam Testing 6"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Step 1: Load the model ===
model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# Build the model by passing a dummy input
_ = model(tf.zeros((1, 128, 128, 3)))

# Wrap Sequential model as Functional if needed to ensure input/output are defined
if isinstance(model, tf.keras.Sequential):
    model.build((None, 128, 128, 3))  # Ensures input shape is known
    model_input = model.input
    model_output = model.output
    model = tf.keras.Model(inputs=model_input, outputs=model_output)
print([layer.name for layer in model.layers])

#     print("‚úÖ Wrapped Sequential model as Functional model.")
# else:
#     print("‚úÖ Model is already a Functional model.")


# === Step 2: Load random test image ===
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
# Check if the directory exists and is not empty
if not os.path.exists(cnn_dataset_path) or not os.listdir(cnn_dataset_path):
    raise FileNotFoundError(f"CNN dataset path not found or empty: {cnn_dataset_path}")

class_folders = os.listdir(cnn_dataset_path)
if not class_folders:
    raise FileNotFoundError(f"No class folders found in {cnn_dataset_path}")
class_folder = random.choice(class_folders)
class_path = os.path.join(cnn_dataset_path, class_folder)

# Check if the class folder exists and is not empty
image_names = os.listdir(class_path)
if not os.path.exists(class_path) or not image_names:
     raise FileNotFoundError(f"Class folder not found or empty: {class_path}")

image_name = random.choice(image_names)
img_path = os.path.join(class_path, image_name)

# Check if the image file exists
if not os.path.exists(img_path):
    raise FileNotFoundError(f"Image file not found: {img_path}")

img = cv2.imread(img_path)
if img is None:
    raise IOError(f"Failed to load image: {img_path}")

img_resized = cv2.resize(img, (128, 128))
img_array = np.expand_dims(img_resized / 255.0, axis=0) # Add batch dimension and normalize

# === Step 3: Grad-CAM Function ===
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2", pred_index=None):
    # Find the last convolutional layer
    last_conv_layer = None
    try:
        last_conv_layer = model.get_layer(name=last_conv_layer_name)
    except ValueError:
        # If not found directly, check inside a 'sequential' layer if the model was wrapped
        try:
            sequential_layer = model.get_layer('sequential')
            last_conv_layer = sequential_layer.get_layer(last_conv_layer_name)
            print(f"‚úÖ Found layer '{last_conv_layer_name}' inside 'sequential'.")
        except ValueError:
            print(f"‚ùå Error: Layer with name '{last_conv_layer_name}' not found in the model or inside 'sequential'.")
            print("Available layers in main model:", [layer.name for layer in model.layers])
            try:
                 print("Available layers in 'sequential':", [layer.name for layer in sequential_layer.layers])
            except:
                 pass # 'sequential' layer might not exist or not have layers
            return None # Return None to indicate failure


    # Create a sub-model that maps the model's input to the outputs
    # of the last convolutional layer and the final output layer.
    # Use model.input explicitly for robustness.
    try:
        grad_model = tf.keras.models.Model(
            inputs=model.input, # Use the main model's input tensor
            outputs=[last_conv_layer.output, model.output] # Output conv features and final predictions
        )
    except Exception as e:
        print(f"‚ùå Error creating grad_model: {e}")
        # Optional: Print model summary to debug inputs/outputs
        # model.summary()
        return None

    # Convert the input image array to a TensorFlow tensor
    img_tensor = tf.convert_to_tensor(img_array, dtype=tf.float32)

    # Use tf.GradientTape to record operations for automatic differentiation
    with tf.GradientTape() as tape:
        # Pass the image through the grad_model to get conv outputs and predictions
        conv_outputs, predictions = grad_model(img_tensor)

        # Ensure predictions are not empty or have an invalid shape
        if predictions is None or predictions.shape is None or predictions.shape[0] == 0 or predictions.shape[1] == 0:
            print("‚ö†Ô∏è Warning: Model predictions are empty or have invalid shape. Cannot determine pred_index.")
            return None

        # Determine the index of the predicted class
        if pred_index is None:
            pred_index = tf.argmax(predictions[0])

        # Select the score of the predicted class from the predictions
        output_class = predictions[:, pred_index]

    # Calculate the gradients of the predicted class score with respect to the
    # output feature maps of the last convolutional layer.
    grads = tape.gradient(output_class, conv_outputs)

    # Compute the mean of the gradients over the height and width dimensions.
    # This gives a single value per channel, representing the importance of each
    # channel for the predicted class.
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))

    # Multiply each channel of the convolutional output feature maps by the
    # corresponding mean gradient and sum across channels.
    # This produces the heatmap, where high values indicate regions
    # that strongly contributed to the predicted class.
    conv_outputs = conv_outputs[0] # Remove the batch dimension
    # Perform element-wise multiplication and then sum across the channel dimension (-1)
    heatmap = tf.reduce_sum(tf.multiply(pooled_grads, conv_outputs), axis=-1)


    # Apply ReLU to the heatmap to keep only positive influences (activations
    # that increased the class score) and normalize to the range [0, 1].
    # Add a small epsilon to the denominator to prevent division by zero.
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

# === Step 4: Generate Grad-CAM ===
# You might need to inspect your model's layers to get the correct name
# print([layer.name for layer in model.layers]) # Uncomment to see main model layer names
# try:
#     print([layer.name for layer in model.get_layer('sequential').layers]) # Uncomment to see Sequential layer names
# except:
#     pass

# Assuming 'conv2d_2' is indeed the name of the last convolutional layer within the Sequential block
last_conv_layer_name_to_use = "conv2d_2"

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name=last_conv_layer_name_to_use)

# === Step 5: Overlay Heatmap ===
def overlay_heatmap(img_rgb, heatmap, alpha=0.5, colormap=cv2.COLORMAP_JET):
    if heatmap is None:
        print("‚ö†Ô∏è Cannot overlay heatmap ‚Äî heatmap generation failed.")
        return img_rgb # Return original RGB image

    # Convert input image to BGR for cv2 operations (cv2.addWeighted expects BGR)
    img_bgr = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2BGR)

    # Resize heatmap to match the dimensions of the *input* image to this function (img_rgb/img_bgr)
    # The heatmap was generated from the conv output size, so it needs resizing.
    heatmap_resized = cv2.resize(heatmap, (img_bgr.shape[1], img_bgr.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized) # Scale to 0-255
    heatmap_color = cv2.applyColorMap(heatmap_normalized, colormap) # Apply colormap

    # Overlay the heatmap on the original image (which is now in BGR format)
    # cv2.addWeighted blends two images. The first image (img_bgr) gets a weight of 1-alpha,
    # and the second image (heatmap_color) gets a weight of alpha.
    overlayed_bgr = cv2.addWeighted(img_bgr, 1 - alpha, heatmap_color, alpha, 0)

    # Convert the final overlayed image back to RGB format for matplotlib display
    overlayed_rgb = cv2.cvtColor(overlayed_bgr, cv2.COLOR_BGR2RGB)
    return overlayed_rgb

# === Step 6: Display ===
# We want to overlay the heatmap on the *resized* image for visual clarity.
# Convert the resized image (img_resized, which is in BGR from cv2.imread)
# to RGB before passing it to the overlay_heatmap function.
if heatmap is not None: # Only attempt to overlay if heatmap was successfully generated
    # Ensure img_resized is in RGB before passing to overlay_heatmap
    overlayed_img = overlay_heatmap(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB), heatmap)
    plt.imshow(overlayed_img)
    plt.title(f"Grad-CAM: {class_folder}")
else:
    print("‚ùå Grad-CAM heatmap generation failed. Displaying original resized image.")
    # Convert img_resized to RGB for matplotlib display
    plt.imshow(cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB))
    plt.title(f"Original Resized Image: {class_folder}")
plt.axis('off')
plt.show()

"""## All model layers"""

print("All model layers:", [layer.name for layer in model.layers])

"""## Sequential Model layers error"""

print("Sequential layers:", [layer.name for layer in model.get_layer('sequential').layers])

"""## GradCam Testing 7"""

import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import cv2
import os
import random

# === Load Model ===
model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# === Force the model to build by passing a dummy input ===
dummy_input = tf.zeros((1, 128, 128, 3))
_ = model(dummy_input)  # Triggers internal call to build

print("‚úÖ Model loaded and built.")

# === Get layer names to confirm Grad-CAM target ===
print("Model Layers:", [layer.name for layer in model.layers])

cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"

# Get random image path
class_folder = random.choice(os.listdir(cnn_dataset_path))
image_path = os.path.join(cnn_dataset_path, class_folder, random.choice(os.listdir(os.path.join(cnn_dataset_path, class_folder))))

# Load and preprocess image
img = cv2.imread(image_path)
img_resized = cv2.resize(img, (128, 128))
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
img_array = np.expand_dims(img_rgb / 255.0, axis=0)

plt.imshow(img_rgb)
plt.title(f"Original Resized Image: {class_folder}")
plt.axis("off")
plt.show()

def overlay_heatmap(original_img, heatmap, alpha=0.5):
    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized)
    heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)
    overlayed = cv2.addWeighted(cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR), 1 - alpha, heatmap_colored, alpha, 0)
    return cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB)

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2")

if heatmap is not None:
    overlayed = overlay_heatmap(img_rgb, heatmap)
    plt.imshow(overlayed)
    plt.title(f"Grad-CAM Heatmap: {class_folder}")
    plt.axis("off")
    plt.show()
else:
    print("‚ùå Grad-CAM heatmap generation failed.")

"""## GradCam Final Model rebuilt with Fresh Layers"""

from tensorflow.keras.models import Model, Sequential, load_model
from tensorflow.keras.layers import Input
from tensorflow.keras.models import clone_model

# Load the saved Sequential model
sequential_model = tf.keras.models.load_model("/content/drive/My Drive/cnn_acne_model.keras")

# Rebuild it layer-by-layer to avoid graph reuse
inputs = Input(shape=(128, 128, 3))
x = inputs

# Clone each layer
for layer in sequential_model.layers:
    layer_config = layer.get_config()
    new_layer = layer.__class__.from_config(layer_config)
    x = new_layer(x)

# Create the new functional model
model = Model(inputs=inputs, outputs=x)

print("‚úÖ Rebuilt Functional model with fresh layers")

"""### Random image choice"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
import os
import random

cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"

# Pick a random image from a class folder
class_folder = random.choice(os.listdir(cnn_dataset_path))
image_path = os.path.join(cnn_dataset_path, class_folder, random.choice(os.listdir(os.path.join(cnn_dataset_path, class_folder))))

# Load and preprocess the image
img = cv2.imread(image_path)
img_resized = cv2.resize(img, (128, 128))
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
img_array = np.expand_dims(img_rgb / 255.0, axis=0)

plt.imshow(img_rgb)
plt.title(f"Original Image: {class_folder}")
plt.axis("off")
plt.show()

"""### GradCam Heatmap generation"""

def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2"):
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Use tf.GradientTape with predict() to avoid internal graph errors
    conv_outputs, predictions = grad_model.predict(img_array)

    pred_index = np.argmax(predictions[0])
    class_channel = predictions[:, pred_index]

    with tf.GradientTape() as tape:
        inputs = tf.cast(img_array, tf.float32)
        tape.watch(inputs)

        # Re-run forward pass manually
        conv_outputs_tf, predictions_tf = grad_model(inputs)
        output = predictions_tf[:, pred_index]

    # Get gradients
    grads = tape.gradient(output, conv_outputs_tf)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))

    # Multiply each channel by the corresponding gradient importance
    conv_outputs_tf = conv_outputs_tf[0]
    heatmap = tf.reduce_sum(conv_outputs_tf * pooled_grads, axis=-1)

    # Normalize the heatmap
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

def overlay_heatmap(original_img, heatmap, alpha=0.5):
    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized)
    heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)
    overlayed = cv2.addWeighted(cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR), 1 - alpha, heatmap_colored, alpha, 0)
    return cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB)

"""### Image with Gradcam Heatmaps"""

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2")

if heatmap is not None:
    overlayed = overlay_heatmap(img_rgb, heatmap)
    plt.imshow(overlayed)
    plt.title(f"Grad-CAM: {class_folder}")
    plt.axis("off")
    plt.show()
else:
    print("‚ùå Grad-CAM heatmap generation failed.")

import os
import random
import cv2
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# --- Step 1: Load a random image ---
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
class_names = ['blackheads', 'cystic', 'nodular', 'papules', 'pustules', 'whiteheads']

class_folder = random.choice(os.listdir(cnn_dataset_path))
image_file = random.choice(os.listdir(os.path.join(cnn_dataset_path, class_folder)))
image_path = os.path.join(cnn_dataset_path, class_folder, image_file)

img = cv2.imread(image_path)
img_resized = cv2.resize(img, (128, 128))
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
img_array = np.expand_dims(img_rgb / 255.0, axis=0)  # shape (1, 128, 128, 3)

# --- Step 2: Predict the class ---
preds = model.predict(img_array)
predicted_class = np.argmax(preds[0])
predicted_label = class_names[predicted_class]
confidence = preds[0][predicted_class]

# --- Step 3: Generate Grad-CAM heatmap ---
def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2"):
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    with tf.GradientTape() as tape:
        inputs = tf.cast(img_array, tf.float32)
        conv_outputs, predictions = grad_model(inputs)
        pred_index = tf.argmax(predictions[0])
        output = predictions[:, pred_index]

    grads = tape.gradient(output, conv_outputs)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))
    conv_outputs = conv_outputs[0]
    heatmap = tf.reduce_sum(conv_outputs * pooled_grads, axis=-1)
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

heatmap = make_gradcam_heatmap(img_array, model)

# --- Step 4: Overlay heatmap ---
def overlay_heatmap(heatmap, image, alpha=0.4):
    heatmap = cv2.resize(heatmap, (image.shape[1], image.shape[0]))
    heatmap_color = cv2.applyColorMap(np.uint8(255 * heatmap), cv2.COLORMAP_JET)
    overlayed = cv2.addWeighted(image, 1 - alpha, heatmap_color, alpha, 0)
    return overlayed

overlay_img = overlay_heatmap(heatmap, img_rgb)

# --- Step 5: Display result ---
plt.figure(figsize=(10, 4))

plt.subplot(1, 2, 1)
plt.imshow(img_rgb)
plt.title("Original Image")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(overlay_img)
plt.title(f"Grad-CAM: {predicted_label} ({confidence:.2f})")
plt.axis("off")

plt.tight_layout()
plt.show()

"""# LIME"""

pred = model.predict(img_array)
print("Prediction shape:", pred.shape)
print("Prediction:", pred)

import os

cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"
class_names = sorted(os.listdir(cnn_dataset_path))
print(class_names)

print(img_array.shape)

"""## LIME Installation"""

!pip install lime

"""## LIME non descriptive explanation with IMAGE"""

print("Model input shape:", model.input_shape)

print("img_rgb shape:", img_rgb.shape)

from lime import lime_image
from skimage.segmentation import mark_boundaries
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf

# Your class names
class_names = ['blackheads', 'cystic', 'nodular', 'papules', 'pustules', 'whiteheads']

# Wrap model prediction to match LIME's expected format
def predict_fn(images):
    resized = tf.image.resize(images, (128, 128)).numpy()  # LIME sends varied sizes
    normalized = resized / 255.0
    return model.predict(normalized)

# Create LIME image explainer
explainer = lime_image.LimeImageExplainer()

# Explain the prediction on your input image (index 0)
explanation = explainer.explain_instance(
    image=img_rgb,                   # RGB image (no batch dim)
    classifier_fn=predict_fn,       # Function to get prediction probs
    top_labels=1,                   # Explain top prediction
    hide_color=0,                   # Color to replace "turned off" pixels
    num_samples=1000                # Number of perturbed samples
)

# Get top predicted class
preds = model.predict(img_array)
predicted_class = np.argmax(preds[0])
predicted_label = class_names[predicted_class]

# Visualize the explanation
temp, mask = explanation.get_image_and_mask(
    label=predicted_class,
    positive_only=True,
    num_features=5,
    hide_rest=False
)

for i, score in enumerate(preds[0]):
    print(f"{class_names[i]}: {score:.4f}")


plt.figure(figsize=(8, 8))
plt.imshow(mark_boundaries(temp / 255.0, mask))
plt.title(f"LIME Explanation: {predicted_label}")
plt.axis("off")
plt.show()

from lime import lime_image
from skimage.segmentation import mark_boundaries
import numpy as np
import matplotlib.pyplot as plt

# Step 1: Run prediction and print class probabilities
preds = model.predict(img_array)

# Class names
class_names = ['blackheads', 'cystic', 'nodular', 'papules', 'pustules', 'whiteheads']

# Print each class confidence
for i, score in enumerate(preds[0]):
    print(f"{class_names[i]}: {score:.4f}")

"""## LIME Descriptive explanation with IMAGE"""

# Step 2: Identify top class and build explanation message
predicted_class = np.argmax(preds[0])
predicted_label = class_names[predicted_class]
confidence = preds[0][predicted_class]

explanation_text = (
    f"Prediction: {predicted_label} ({confidence * 100:.2f}% confidence)\n"
    "Highlighted regions most influenced the model's decision."
)

from lime import lime_image

# Step 3: LIME explainer instance
explainer = lime_image.LimeImageExplainer()

# Function to match LIME's input format
def predict_fn(images):
    resized = tf.image.resize(images, (128, 128)).numpy()  # LIME sends varied sizes
    normalized = resized / 255.0
    return model.predict(normalized)

# Explain the input image (img_rgb must be RGB format)
explanation = explainer.explain_instance(
    image=img_rgb,
    classifier_fn=predict_fn,
    top_labels=1,
    hide_color=0,
    num_samples=1000
)

from lime import lime_image

# Step 3: LIME explainer instance
explainer = lime_image.LimeImageExplainer()

# Function to match LIME's input format
def predict_fn(images):
    resized = tf.image.resize(images, (128, 128)).numpy()  # LIME sends varied sizes
    normalized = resized / 255.0
    return model.predict(normalized)

# Explain the input image (img_rgb must be RGB format)
explanation = explainer.explain_instance(
    image=img_rgb,
    classifier_fn=predict_fn,
    top_labels=1,
    hide_color=0,
    num_samples=1000
)

from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
plt.imshow(mark_boundaries(temp / 255.0, mask))

# Clear explanation above and below the image
plt.suptitle("LIME Explanation", fontsize=16, y=1.03)
plt.title(explanation_text, fontsize=10)
plt.axis("off")
plt.tight_layout()
plt.show()

from skimage.segmentation import mark_boundaries
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 8))
plt.imshow(mark_boundaries(temp / 255.0, mask))

# Clear explanation above and below the image
plt.suptitle("LIME Explanation", fontsize=16, y=1.03)
plt.title(explanation_text, fontsize=12)
plt.axis("off")
plt.tight_layout()
plt.show()

"""# TESTING with GradCAM and LIME"""

import os, random
import cv2
import numpy as np
import matplotlib.pyplot as plt

# Dataset path
cnn_dataset_path = "/content/drive/My Drive/cnn_dataset"

# Pick random image from random class
class_folder = random.choice(os.listdir(cnn_dataset_path))
image_path = os.path.join(cnn_dataset_path, class_folder, random.choice(os.listdir(os.path.join(cnn_dataset_path, class_folder))))

# Load and preprocess image
img = cv2.imread(image_path)
img_resized = cv2.resize(img, (128, 128))
img_rgb = cv2.cvtColor(img_resized, cv2.COLOR_BGR2RGB)
img_array = np.expand_dims(img_rgb / 255.0, axis=0)  # normalized

# Show original image
plt.imshow(img_rgb)
plt.title(f"Random Image: {class_folder}")
plt.axis("off")
plt.show()

# Predict
preds = model.predict(img_array)
class_names = ['blackheads', 'cystic', 'nodular', 'papules', 'pustules', 'whiteheads']
predicted_class = np.argmax(preds[0])
predicted_label = class_names[predicted_class]
confidence = preds[0][predicted_class]

def make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2"):
    grad_model = tf.keras.models.Model(
        inputs=model.input,
        outputs=[model.get_layer(last_conv_layer_name).output, model.output]
    )

    # Use tf.GradientTape with predict() to avoid internal graph errors
    conv_outputs, predictions = grad_model.predict(img_array)

    pred_index = np.argmax(predictions[0])
    class_channel = predictions[:, pred_index]

    with tf.GradientTape() as tape:
        inputs = tf.cast(img_array, tf.float32)
        tape.watch(inputs)

        # Re-run forward pass manually
        conv_outputs_tf, predictions_tf = grad_model(inputs)
        output = predictions_tf[:, pred_index]

    # Get gradients
    grads = tape.gradient(output, conv_outputs_tf)[0]
    pooled_grads = tf.reduce_mean(grads, axis=(0, 1))

    # Multiply each channel by the corresponding gradient importance
    conv_outputs_tf = conv_outputs_tf[0]
    heatmap = tf.reduce_sum(conv_outputs_tf * pooled_grads, axis=-1)

    # Normalize the heatmap
    heatmap = tf.maximum(heatmap, 0) / (tf.reduce_max(heatmap) + 1e-10)
    return heatmap.numpy()

def overlay_heatmap(original_img, heatmap, alpha=0.5):
    heatmap_resized = cv2.resize(heatmap, (original_img.shape[1], original_img.shape[0]))
    heatmap_normalized = np.uint8(255 * heatmap_resized)
    heatmap_colored = cv2.applyColorMap(heatmap_normalized, cv2.COLORMAP_JET)
    overlayed = cv2.addWeighted(cv2.cvtColor(original_img, cv2.COLOR_RGB2BGR), 1 - alpha, heatmap_colored, alpha, 0)
    return cv2.cvtColor(overlayed, cv2.COLOR_BGR2RGB)

heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name="conv2d_2")
gradcam_result = overlay_heatmap(img_rgb, heatmap)

import matplotlib.pyplot as plt

plt.figure(figsize=(6, 6))
plt.imshow(gradcam_result)
plt.title(f"Grad-CAM: {class_folder} ({confidence * 100:.2f}% confidence)")
plt.axis("off")
plt.tight_layout()
plt.show()

from lime import lime_image
from skimage.segmentation import mark_boundaries

# Step 1: Wrap model prediction for LIME
def predict_fn(images):
    images = np.array(images) / 255.0  # normalize if not already
    return model.predict(images)

# Step 2: Create explainer instance
explainer = lime_image.LimeImageExplainer()

# Step 3: Explain the instance
explanation = explainer.explain_instance(
    image=img_rgb,               # Input image (RGB, no batch dim)
    classifier_fn=predict_fn,    # Your model wrapped for LIME
    top_labels=1,                # Explain top predicted class only
    hide_color=0,                # Black out masked regions
    num_samples=1000             # Number of perturbations
)

# Get the mask + highlighted image for top prediction
temp, mask = explanation.get_image_and_mask(
    label=predicted_class,
    positive_only=True,
    num_features=5,
    hide_rest=False
)

# Save LIME visualization for comparison
lime_result = mark_boundaries(temp / 255.0, mask)

plt.figure(figsize=(6, 6))
plt.imshow(lime_result)
plt.title(f"LIME: {class_folder} ({confidence * 100:.2f}% confidence)")
plt.axis("off")
plt.tight_layout()
plt.show()

plt.figure(figsize=(12, 6))

# Grad-CAM subplot
plt.subplot(1, 2, 1)
plt.imshow(gradcam_result)
plt.title(f"Grad-CAM: {class_folder}\n({confidence * 100:.2f}% confidence)")
plt.axis("off")

# LIME subplot
plt.subplot(1, 2, 2)
plt.imshow(lime_result)
plt.title(f"LIME: {class_folder}\n({confidence * 100:.2f}% confidence)")
plt.axis("off")

plt.suptitle("Model Explanation Comparison", fontsize=16)
plt.tight_layout()
plt.show()

"""# TESTING with YOLOV8 and CNN"""

# Install ultralytics
!pip install ultralytics

from ultralytics import YOLO

# Load your YOLOv8 model (adjust path to your weights)
yolo_model = YOLO("/content/drive/MyDrive/acne_detection_yolov8/yolov8_finetune_acne3/weights/best.pt")

# Run detection on your image
yolo_results = yolo_model.predict(img_rgb, conf=0.22, verbose=False)[0]  # returns boxes per image

# Extract bounding boxes
boxes = yolo_results.boxes.xyxy.cpu().numpy().astype(int)
print(f"Detected {len(boxes)} acne regions")

# Extract the first detected box (since you only have 1 for now)
x1, y1, x2, y2 = boxes[0]  # already cast to int

# Crop from original image
crop = img_rgb[y1:y2, x1:x2]

# Resize to match CNN input
crop_resized = cv2.resize(crop, (128, 128))

# Normalize for CNN
img_array = np.expand_dims(crop_resized / 255.0, axis=0)

preds = model.predict(img_array)
predicted_class = np.argmax(preds[0])
predicted_label = class_names[predicted_class]
confidence = preds[0][predicted_class]

print(f"CNN Prediction: {predicted_label} ({confidence * 100:.2f}%)")

# Clone and pad
yolo_vis = cv2.copyMakeBorder(img_rgb.copy(), 40, 0, 0, 0, cv2.BORDER_CONSTANT, value=(255, 255, 255))

# Get box and confidence
x1, y1, x2, y2 = boxes[0]
conf_yolo = yolo_results.boxes.conf[0].item() * 100

# Draw box
cv2.rectangle(yolo_vis, (x1, y1 + 40), (x2, y2 + 40), (0, 255, 0), 2)

# Add confidence score
cv2.putText(
    yolo_vis,
    f"{conf_yolo:.2f}%",  # Only the score
    (x1, y1 + 30),
    cv2.FONT_HERSHEY_SIMPLEX,
    0.6,
    (0, 128, 0),
    2
)

cnn_vis = cv2.copyMakeBorder(crop.copy(), 40, 0, 0, 0, cv2.BORDER_CONSTANT, value=(255, 255, 255))

# CNN confidence already available
cv2.putText(
    cnn_vis,
    f"{confidence * 100:.2f}%",  # Only the score
    (10, 30),
    cv2.FONT_HERSHEY_SIMPLEX,
    0.6,
    (255, 0, 0),
    2
)

yolo_display = cv2.resize(yolo_vis, (300, 300))
cnn_display = cv2.resize(cnn_vis, (300, 300))

plt.figure(figsize=(12, 6))

plt.subplot(1, 2, 1)
plt.imshow(yolo_display)
plt.title("YOLOv8 Detection")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(cnn_display)
plt.title("CNN Classification")
plt.axis("off")

plt.suptitle("YOLO vs CNN: Confidence Score Comparison", fontsize=16)
plt.tight_layout()
plt.show()